{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bb2127-72fb-4e65-96da-2c66f41071d2",
   "metadata": {},
   "source": [
    "Note: everything included and mention in this notebook like images, pdf and result output is in the zip folder. Except chunks, courseTaken csv files because these both are very large files. Apart from this everything is included in zip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9ede2-ea1c-46d6-b10e-2b9ad09c1035",
   "metadata": {},
   "source": [
    "1: both parts are shown below  (also included in zip folder with name bda_a2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea63fe-4376-48b4-9253-2cc906ebfce0",
   "metadata": {},
   "source": [
    "![for aggregated-A](bda_a2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7443808-aa2d-4c34-b567-a9aa9f607298",
   "metadata": {},
   "source": [
    "2: cant include chunk files in zip folder, so putting terminal screenshot here of snakemake -- summary when snakefile had split rule only:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d16bc-7011-4699-a1f3-1ee09844d8e0",
   "metadata": {},
   "source": [
    "![for aggregated-A](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac6098-4f6a-499d-83ac-489451c6d805",
   "metadata": {},
   "source": [
    "2 (a): Why canâ€™t we use a simple rule for this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582c5a6-663f-466c-b2c9-af5017cdb3a1",
   "metadata": {},
   "source": [
    "we have done 2 unique things here: use of checkpoint and splitting large file into small chunk files. \n",
    "Checkpoint: this is generally odne to determine workflow during runtime, because some output files of rule are needed to determine the rest of the workflow. TO run other rules based on the output of this checkpoint. \n",
    "splitting large files: usefule because we can do parallel processsing which can significantly speed up the processing time. in this case, each chunk file can be separately processed by 'sum_grades' rule. there might be some other reasons too like memory limitations, progress monitoring in the terminal or other CLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f02ff-11d7-4070-964e-30cc70716da5",
   "metadata": {},
   "source": [
    "How many chunk files are created in this step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746c25d-acce-4783-842a-ab3fb8bf2818",
   "metadata": {},
   "source": [
    "For this part, I added a new file in split.py script and also put one more output (num_chunks) in split rule of snakefile. So, in the end result i got two files num_chunks-{letter}.txt which contains number of chunk files for each part (just like we wrote 1 million in testoutput.txt in previous assignment). I will still mention the output here: 203 for course A and 153 for course B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357e2fb-1cd0-4449-8a82-49df9aef6f17",
   "metadata": {},
   "source": [
    "2(b): you will find the files with extension .sum in chunks folder only. But I have not included chunks in zip folder because of large data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbb34f-44e9-4dee-b15a-d54ff5040855",
   "metadata": {},
   "source": [
    "2(c): you will find the aggregate-A.txt and aggregate-B.txt files in zip folder only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c0a83-f4c8-4656-bd6d-cda7a5b38479",
   "metadata": {},
   "source": [
    "2(d) You only specify the output filename aggregated-A.txt of what you eventually want to see. How does this prop- agate information through the workflow specified by the Snakefile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32815b50-788b-458b-9879-068d4a6a78c0",
   "metadata": {},
   "source": [
    "DAG is created based on input and output file mentioned in the rules, but it also includes any dependencies between rules. when we are specifying target like 'aggregate-A.txt', snakemake try to create a plan to produce that file based on the rules in snakefile. Hence, snakemake looks at the aggregate rule ( whihc produce this output file that mathces 'aggregate-{letter}.txt') and then determines what input files are needed. it sees that it needs output from 'sum_grades' rule and then snakemake realize that 'sum_grades' rules needs output form 'split'. this continues until snakemake rule doesnot need any more inputs. In this way, specifying an output file of the workflow leads Snakemake to propagate information through the workflow to determine what rules need to be run, and in what order, to eventually produce the desired output file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96dd45-3a55-4477-8270-befbb08873a2",
   "metadata": {},
   "source": [
    "Which parts of this workflow is performing map tasks, which are reducers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f90e4-8d8b-4e98-80f6-7738f791b5be",
   "metadata": {},
   "source": [
    "for map reduce programming model, map tasks are perform computations on chunk and reduce tasks aggregate results from map tasks to giv efinal oputput. Map tasks: are done by 'split' (creating smaller chunk from large file) and 'sum_grades' (performing computation on each of chunk indeopendently). Reduce tasks: done by 'aggregate rule'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be3b9e-c828-4251-9679-0ccf83951238",
   "metadata": {},
   "source": [
    "3: these are the visualization for course-A and course-B respectively. (also included in zip folder with name aggregated-A.png and aggregated-B.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c88a3-faf9-44a8-979b-1a71f8006dba",
   "metadata": {},
   "source": [
    "![for aggregated-A](aggregated-A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e9d463-d337-4e7f-9ce3-8045293e372b",
   "metadata": {},
   "source": [
    "![optional alt text](aggregated-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a7bab-193a-4f73-9ae9-30494871be8b",
   "metadata": {},
   "source": [
    "4: Create a visual graph of the workflow you created in tasks 2-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf830e3-8455-41f7-a393-bca0d8c55f01",
   "metadata": {},
   "source": [
    "to visualize it, it tried to do it with graphviz but the workflow generate by command 'snakemake --dag aggregated-A.png aggregated-B.png | dot -Tpdf > dag.pdf' is way too large. Have to zoom in a lot to even see it. So i have tried to put two screenshots of the visualtization pdf 'dag.pdf' for your convinience. screenshots- dag1.png and dag2.png for course-A and course-B  can be seen below (also in zip file). dag.pdf can be found in zip file too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44717520-f1f4-42e4-8852-abeb541d2d89",
   "metadata": {},
   "source": [
    "![optional alt text](dag1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5462756-3b60-4d75-9711-1bd7ee01a07f",
   "metadata": {},
   "source": [
    "![optional alt text](dag2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d0b55-1c0f-4da8-8801-ff9685fb3d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
